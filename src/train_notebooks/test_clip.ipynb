{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"Clip_classification.ipynb\"",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8cccd551d4ee4fa5b85bacf03259a2c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9f8c53166bb14e84866426ee057a122f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d5d4d32ea2204beb90006667a0335527",
              "IPY_MODEL_7dc1014db65b41638a95cb9aae3555a4",
              "IPY_MODEL_d24689a9155a492680f7ce9cde2a624f"
            ]
          }
        },
        "9f8c53166bb14e84866426ee057a122f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5d4d32ea2204beb90006667a0335527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9853f0fa4f3b4e87bcb196ad8ef56cdf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b41a5728f23c4220916e68ed170daeef"
          }
        },
        "7dc1014db65b41638a95cb9aae3555a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8ab2f636ee6b45079e0d1336f3f06695",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 297,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 297,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_561e0c4566a64056b6b0bf1a9011f0ea"
          }
        },
        "d24689a9155a492680f7ce9cde2a624f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6cc733f0e745489e82f66b3ecf18c623",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 297/297 [00:00&lt;00:00, 6.64kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_418fc1c291a54b499d58032bc804a857"
          }
        },
        "9853f0fa4f3b4e87bcb196ad8ef56cdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b41a5728f23c4220916e68ed170daeef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ab2f636ee6b45079e0d1336f3f06695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "561e0c4566a64056b6b0bf1a9011f0ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6cc733f0e745489e82f66b3ecf18c623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "418fc1c291a54b499d58032bc804a857": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b9c866c8f2b4e96ae14f22c0c9f28db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_15e5cb6197bb4dd299b2b4a0cbb59fda",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d885239c8e14158894563d493f6aa42",
              "IPY_MODEL_3a502082d8d64b8faacc16b167739a79",
              "IPY_MODEL_3a3887d9a7b74bd191131d3e0b0ceedb"
            ]
          }
        },
        "15e5cb6197bb4dd299b2b4a0cbb59fda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d885239c8e14158894563d493f6aa42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a7c53d68edfd4fc882b632f88cacc725",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb0d1636df0049de91c3de150d105ca3"
          }
        },
        "3a502082d8d64b8faacc16b167739a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_22b662933ae94fc7beab2e136d8e05ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 804,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 804,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1062d79af65845baa87108f8cf39de8d"
          }
        },
        "3a3887d9a7b74bd191131d3e0b0ceedb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_90856544d6334fa8b9dd6e9a231a4f3c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 804/804 [00:00&lt;00:00, 21.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2fe398130b164adcbe749213ad92ae3a"
          }
        },
        "a7c53d68edfd4fc882b632f88cacc725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb0d1636df0049de91c3de150d105ca3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22b662933ae94fc7beab2e136d8e05ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1062d79af65845baa87108f8cf39de8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90856544d6334fa8b9dd6e9a231a4f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2fe398130b164adcbe749213ad92ae3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "805f38c0f21f4259ac612b6bb097e59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e1f5a1c9c7604a5a85bc54d759717613",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_68c18663a41048c3b3c7ceba9044cbc2",
              "IPY_MODEL_88fe282fd2da4d07ab79bcea7c40e897",
              "IPY_MODEL_eae3493451d64c01bb270b06ab0ba49c"
            ]
          }
        },
        "e1f5a1c9c7604a5a85bc54d759717613": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68c18663a41048c3b3c7ceba9044cbc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5aa517591e4b4bc2861a2518b3dbc98b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e559f92a7154348b4f4f6c5b9b03a24"
          }
        },
        "88fe282fd2da4d07ab79bcea7c40e897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5d8baf215dbf4d669141957d7fa37346",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ddac22eb2ef406eb684a9d7274dfb45"
          }
        },
        "eae3493451d64c01bb270b06ab0ba49c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_884dd12b0faf4c4f9959ad73e5e3932c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 972k/972k [00:00&lt;00:00, 5.58MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0752401d21cb43c58a46df646d047703"
          }
        },
        "5aa517591e4b4bc2861a2518b3dbc98b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e559f92a7154348b4f4f6c5b9b03a24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d8baf215dbf4d669141957d7fa37346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ddac22eb2ef406eb684a9d7274dfb45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "884dd12b0faf4c4f9959ad73e5e3932c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0752401d21cb43c58a46df646d047703": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ff46ce51f9a4be78d875279ede81e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9f2a0434b3d84832877f80999c117d30",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_47c756d7b99a4c62aa5d0932d144e608",
              "IPY_MODEL_92326fc1989448f4858ae4f8bc4e2ac7",
              "IPY_MODEL_6f8c3c6ca57b4c9f9c1a3aade822b333"
            ]
          }
        },
        "9f2a0434b3d84832877f80999c117d30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "47c756d7b99a4c62aa5d0932d144e608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2778523c0f214ee7b350c930526125d9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_050bd14c1fd84c01adc32602cd3bd88c"
          }
        },
        "92326fc1989448f4858ae4f8bc4e2ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_14b227c9dd224c1b893f495f1f87e9e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3f097c16d4c840c6b7ff6e97dd3d7afd"
          }
        },
        "6f8c3c6ca57b4c9f9c1a3aade822b333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4b65d537b2f64146ae4e1bd701370c09",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 2.62kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_951c78f6efb6451594cf049f9ecde5fa"
          }
        },
        "2778523c0f214ee7b350c930526125d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "050bd14c1fd84c01adc32602cd3bd88c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14b227c9dd224c1b893f495f1f87e9e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3f097c16d4c840c6b7ff6e97dd3d7afd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b65d537b2f64146ae4e1bd701370c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "951c78f6efb6451594cf049f9ecde5fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab350b1c731d4a19b683d8e1dea0c9c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dddc7dc0a4114a2eb7390eb3aa099435",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e208db094e3b468ba1d90e352875597a",
              "IPY_MODEL_371e9a79dea84a6b8aaf84fb86190268",
              "IPY_MODEL_a2d453dae65f42089411a44c1675b853"
            ]
          }
        },
        "dddc7dc0a4114a2eb7390eb3aa099435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e208db094e3b468ba1d90e352875597a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ab2d6f184a8143c78d1593b8436ffb4d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb65b7694d724291853286eb607a219e"
          }
        },
        "371e9a79dea84a6b8aaf84fb86190268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4d24a6a3cee2493a8cf2e5239890fe84",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 711497527,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 711497527,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_10e07e6690dd4602b4d3242f14cbae70"
          }
        },
        "a2d453dae65f42089411a44c1675b853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9151d4fa6dc64e9680905eda437c0067",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 679M/679M [00:26&lt;00:00, 27.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08601988109048978651e99a2c978c8f"
          }
        },
        "ab2d6f184a8143c78d1593b8436ffb4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb65b7694d724291853286eb607a219e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d24a6a3cee2493a8cf2e5239890fe84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "10e07e6690dd4602b4d3242f14cbae70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9151d4fa6dc64e9680905eda437c0067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08601988109048978651e99a2c978c8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQBvkd23pNRo",
        "outputId": "ff6efa6e-c7cd-43d0-e8f5-794676e34520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/openai/CLIP\n",
        "!pip install ftfy regex tqdm omegaconf pytorch-lightning torch torchvision transformers\n",
        "!wget https://www.dropbox.com/s/2oxu7hw0y9fwdqs/M-BERT-Base-69-ViT%20Linear%20Weights.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CLIP'...\n",
            "remote: Enumerating objects: 185, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 185 (delta 7), reused 13 (delta 4), pack-reused 168\u001b[K\n",
            "Receiving objects: 100% (185/185), 8.90 MiB | 29.60 MiB/s, done.\n",
            "Resolving deltas: 100% (89/89), done.\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Collecting omegaconf\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.5.8-py3-none-any.whl (526 kB)\n",
            "\u001b[K     |████████████████████████████████| 526 kB 47.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 59.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Collecting PyYAML>=5.1.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 54.5 MB/s \n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 57.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (1.19.5)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (21.3)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.6.2-py3-none-any.whl (332 kB)\n",
            "\u001b[K     |████████████████████████████████| 332 kB 62.2 MB/s \n",
            "\u001b[?25hCollecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 58.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (3.10.0.2)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 52.4 MB/s \n",
            "\u001b[?25hCollecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning) (2.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.23.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning) (3.0.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.43.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 56.8 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 52.2 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (2.0.10)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 66.0 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 52.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning) (21.4.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 63.3 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Building wheels for collected packages: ftfy, antlr4-python3-runtime, future\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=fe6413bbdb147b25c0d096857f570be8aadb0f87d82934e6c6e70c47c6e2ebc4\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=dc1418b8a7c7abe71d4dfa53c7075c6409428393ab7a84047c2e693f18b5841a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=ec5ab8b1e319ba07e3472eb2906090f60b2779eb1e78720e0c0982f100fb37db\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built ftfy antlr4-python3-runtime future\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, PyYAML, fsspec, aiohttp, torchmetrics, tokenizers, sacremoses, pyDeprecate, huggingface-hub, future, antlr4-python3-runtime, transformers, pytorch-lightning, omegaconf, ftfy\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "Successfully installed PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 antlr4-python3-runtime-4.8 async-timeout-4.0.2 asynctest-0.13.0 frozenlist-1.2.0 fsspec-2022.1.0 ftfy-6.0.3 future-0.18.2 huggingface-hub-0.4.0 multidict-5.2.0 omegaconf-2.1.1 pyDeprecate-0.3.1 pytorch-lightning-1.5.8 sacremoses-0.0.47 tokenizers-0.10.3 torchmetrics-0.6.2 transformers-4.15.0 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-15 20:07:56--  https://www.dropbox.com/s/2oxu7hw0y9fwdqs/M-BERT-Base-69-ViT%20Linear%20Weights.pkl\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/2oxu7hw0y9fwdqs/M-BERT-Base-69-ViT%20Linear%20Weights.pkl [following]\n",
            "--2022-01-15 20:07:56--  https://www.dropbox.com/s/raw/2oxu7hw0y9fwdqs/M-BERT-Base-69-ViT%20Linear%20Weights.pkl\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb1f5933557f2983bd649085427.dl.dropboxusercontent.com/cd/0/inline/Bd34uXOMw6RC_3fOez4F4rISd_wSMgtZkizKtyJewbmIJXYhQc_BvZwjq3ZN5o0JKDnyJRid_MRa1IuGIhSbbHjYePm-KLhro6T4Jd2asCLNwaq32H5jktddkqCRp_ynoe1TLBm9Tmns3cYb4GbfJ9Dp/file# [following]\n",
            "--2022-01-15 20:07:57--  https://ucb1f5933557f2983bd649085427.dl.dropboxusercontent.com/cd/0/inline/Bd34uXOMw6RC_3fOez4F4rISd_wSMgtZkizKtyJewbmIJXYhQc_BvZwjq3ZN5o0JKDnyJRid_MRa1IuGIhSbbHjYePm-KLhro6T4Jd2asCLNwaq32H5jktddkqCRp_ynoe1TLBm9Tmns3cYb4GbfJ9Dp/file\n",
            "Resolving ucb1f5933557f2983bd649085427.dl.dropboxusercontent.com (ucb1f5933557f2983bd649085427.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to ucb1f5933557f2983bd649085427.dl.dropboxusercontent.com (ucb1f5933557f2983bd649085427.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/Bd2uzsJoFofYII4_XrAgok8kwpPUlcnbsCSwmn-4aQQFBM2qHzuPVTnQd6W8x5F1Uafpbn8ET4i_ZX0D9v67pETrZeeLWBJPlp596GA9G-o1E9OCa6F6A0aCsWpTk10KhLnB2ZE_S0xJmu3IzDmXcCkeNDnQPwXrTnsa46LRm69kIzodG48NY9kGg4hL6LNlA2tgugVjYHMbLKKJ8T88FTdv-dhDls9ymFLcVuCU1KNiQ0EM18bwTrDiUxan7ViMQoOdYBSUr07B4vqlJPb2wK8Jf49XVTvl2DtjCa8v0dRcW-BSdrl5VcH3-ZDenp3l7ZHoHuOHK1Q7NmiDIO8UriHnmAslfDaHGpRRHDEEBJvHTqlM5nag99HSvPHTsGfCJkU/file [following]\n",
            "--2022-01-15 20:07:57--  https://ucb1f5933557f2983bd649085427.dl.dropboxusercontent.com/cd/0/inline2/Bd2uzsJoFofYII4_XrAgok8kwpPUlcnbsCSwmn-4aQQFBM2qHzuPVTnQd6W8x5F1Uafpbn8ET4i_ZX0D9v67pETrZeeLWBJPlp596GA9G-o1E9OCa6F6A0aCsWpTk10KhLnB2ZE_S0xJmu3IzDmXcCkeNDnQPwXrTnsa46LRm69kIzodG48NY9kGg4hL6LNlA2tgugVjYHMbLKKJ8T88FTdv-dhDls9ymFLcVuCU1KNiQ0EM18bwTrDiUxan7ViMQoOdYBSUr07B4vqlJPb2wK8Jf49XVTvl2DtjCa8v0dRcW-BSdrl5VcH3-ZDenp3l7ZHoHuOHK1Q7NmiDIO8UriHnmAslfDaHGpRRHDEEBJvHTqlM5nag99HSvPHTsGfCJkU/file\n",
            "Reusing existing connection to ucb1f5933557f2983bd649085427.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1575117 (1.5M) [application/octet-stream]\n",
            "Saving to: ‘M-BERT-Base-69-ViT Linear Weights.pkl’\n",
            "\n",
            "M-BERT-Base-69-ViT  100%[===================>]   1.50M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-01-15 20:07:58 (13.4 MB/s) - ‘M-BERT-Base-69-ViT Linear Weights.pkl’ saved [1575117/1575117]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC3n7PXubDnI",
        "outputId": "386d7f42-6439-4f43-b59f-a94d9cbc4245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import zipfile\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/ivision/parser_video_dtp_5_720p.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('/content/drive/MyDrive/ivision/')"
      ],
      "metadata": {
        "id": "5QGaWvJfyens"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dtp_ids = [\n",
        "    # 1,\n",
        "    2,\n",
        "    # 4,\n",
        "    5,\n",
        "    7,\n",
        "    8,\n",
        "    9,\n",
        "    10,\n",
        "    11,\n",
        "    12,\n",
        "    13,\n",
        "    14,\n",
        "    15,\n",
        "    21,\n",
        "    # 22,\n",
        "    24,\n",
        "    27,\n",
        "    33,\n",
        "    36,\n",
        "    50]"
      ],
      "metadata": {
        "id": "8nKnibcb1HUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZoB-tEzP1VCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHxbDTKuo1_g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195,
          "referenced_widgets": [
            "8cccd551d4ee4fa5b85bacf03259a2c3",
            "9f8c53166bb14e84866426ee057a122f",
            "d5d4d32ea2204beb90006667a0335527",
            "7dc1014db65b41638a95cb9aae3555a4",
            "d24689a9155a492680f7ce9cde2a624f",
            "9853f0fa4f3b4e87bcb196ad8ef56cdf",
            "b41a5728f23c4220916e68ed170daeef",
            "8ab2f636ee6b45079e0d1336f3f06695",
            "561e0c4566a64056b6b0bf1a9011f0ea",
            "6cc733f0e745489e82f66b3ecf18c623",
            "418fc1c291a54b499d58032bc804a857",
            "5b9c866c8f2b4e96ae14f22c0c9f28db",
            "15e5cb6197bb4dd299b2b4a0cbb59fda",
            "4d885239c8e14158894563d493f6aa42",
            "3a502082d8d64b8faacc16b167739a79",
            "3a3887d9a7b74bd191131d3e0b0ceedb",
            "a7c53d68edfd4fc882b632f88cacc725",
            "eb0d1636df0049de91c3de150d105ca3",
            "22b662933ae94fc7beab2e136d8e05ac",
            "1062d79af65845baa87108f8cf39de8d",
            "90856544d6334fa8b9dd6e9a231a4f3c",
            "2fe398130b164adcbe749213ad92ae3a",
            "805f38c0f21f4259ac612b6bb097e59c",
            "e1f5a1c9c7604a5a85bc54d759717613",
            "68c18663a41048c3b3c7ceba9044cbc2",
            "88fe282fd2da4d07ab79bcea7c40e897",
            "eae3493451d64c01bb270b06ab0ba49c",
            "5aa517591e4b4bc2861a2518b3dbc98b",
            "7e559f92a7154348b4f4f6c5b9b03a24",
            "5d8baf215dbf4d669141957d7fa37346",
            "4ddac22eb2ef406eb684a9d7274dfb45",
            "884dd12b0faf4c4f9959ad73e5e3932c",
            "0752401d21cb43c58a46df646d047703",
            "4ff46ce51f9a4be78d875279ede81e60",
            "9f2a0434b3d84832877f80999c117d30",
            "47c756d7b99a4c62aa5d0932d144e608",
            "92326fc1989448f4858ae4f8bc4e2ac7",
            "6f8c3c6ca57b4c9f9c1a3aade822b333",
            "2778523c0f214ee7b350c930526125d9",
            "050bd14c1fd84c01adc32602cd3bd88c",
            "14b227c9dd224c1b893f495f1f87e9e0",
            "3f097c16d4c840c6b7ff6e97dd3d7afd",
            "4b65d537b2f64146ae4e1bd701370c09",
            "951c78f6efb6451594cf049f9ecde5fa",
            "ab350b1c731d4a19b683d8e1dea0c9c8",
            "dddc7dc0a4114a2eb7390eb3aa099435",
            "e208db094e3b468ba1d90e352875597a",
            "371e9a79dea84a6b8aaf84fb86190268",
            "a2d453dae65f42089411a44c1675b853",
            "ab2d6f184a8143c78d1593b8436ffb4d",
            "fb65b7694d724291853286eb607a219e",
            "4d24a6a3cee2493a8cf2e5239890fe84",
            "10e07e6690dd4602b4d3242f14cbae70",
            "9151d4fa6dc64e9680905eda437c0067",
            "08601988109048978651e99a2c978c8f"
          ]
        },
        "outputId": "c44c633e-b7df-4688-cfff-dfcaeaed62c7"
      },
      "source": [
        "\n",
        "import torch\n",
        "from CLIP import clip\n",
        "from PIL import Image\n",
        "from torch import nn\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import time\n",
        "all_time = 0\n",
        "model, preprocess = clip.load(\"ViT-B/32\", device=device,jit=False)\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "\n",
        "class MultilingualClip(torch.nn.Module):\n",
        "    def __init__(self, model_name, tokenizer_name, head_name, weights_dir='/content/'):\n",
        "        super().__init__()\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer_name = tokenizer_name\n",
        "        self.head_path = weights_dir + head_name\n",
        "\n",
        "        self.tokenizer = transformers.AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "        self.transformer = transformers.AutoModel.from_pretrained(model_name)\n",
        "        self.clip_head = torch.nn.Linear(in_features=768, out_features=640)\n",
        "        self._load_head()\n",
        "\n",
        "    def forward(self, txt):\n",
        "        txt_tok = self.tokenizer(txt, padding=True, return_tensors='pt')\n",
        "        \n",
        "        embs = self.transformer(**txt_tok)[0]\n",
        "        att = txt_tok['attention_mask']\n",
        "        embs = (embs * att.unsqueeze(2)).sum(dim=1) / att.sum(dim=1)[:, None]\n",
        "        return self.clip_head(embs)\n",
        "\n",
        "    def _load_head(self):\n",
        "        with open(self.head_path, 'rb') as f:\n",
        "            lin_weights = pickle.loads(f.read())\n",
        "        self.clip_head.weight = torch.nn.Parameter(torch.tensor(lin_weights[0]).float().t())\n",
        "        self.clip_head.bias = torch.nn.Parameter(torch.tensor(lin_weights[1]).float())\n",
        "\n",
        "\n",
        "AVAILABLE_MODELS = { \n",
        "    'M-BERT-Base-ViT-B': {\n",
        "        'model_name': 'M-CLIP/M-BERT-Base-ViT-B',\n",
        "        'tokenizer_name': 'M-CLIP/M-BERT-Base-ViT-B',\n",
        "        'head_name': 'M-BERT-Base-69-ViT Linear Weights.pkl'\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "def load_model(name):\n",
        "    config = AVAILABLE_MODELS[name]\n",
        "    return MultilingualClip(**config)\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "text_model = load_model('M-BERT-Base-ViT-B')\n",
        "\n",
        "# text_model.to(device)\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def max_cosine_images(image_paths,label):\n",
        "  \"\"\"\n",
        "  image_paths: массив путей к файлам в которых ищем\n",
        "  label : текстовое описание того что ищем \n",
        "  \"\"\"\n",
        "  cos = nn.CosineSimilarity(dim=1, eps=1e-32)\n",
        "  \n",
        "  \n",
        "\n",
        "  embed = text_model(label)\n",
        "  text_features = embed[:,:512]\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    max = 0\n",
        "    max_score_image = None\n",
        "\n",
        "    for image_p in image_paths:\n",
        "      \n",
        "      \n",
        "      image= preprocess(Image.open(image_p)).unsqueeze(0).to(device)\n",
        "  \n",
        "\n",
        "      image_features = model.encode_image(image)\n",
        "\n",
        "      \n",
        "      \n",
        "        \n",
        "\n",
        "      if cosine>max:\n",
        "        max = cosine\n",
        "        path = image_p\n",
        "        max_score_image  = image\n",
        "        \n",
        "\n",
        "    \n",
        "    return max, max_score_image,path \n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 338M/338M [00:02<00:00, 167MiB/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cccd551d4ee4fa5b85bacf03259a2c3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/297 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b9c866c8f2b4e96ae14f22c0c9f28db",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/804 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "805f38c0f21f4259ac612b6bb097e59c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/972k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ff46ce51f9a4be78d875279ede81e60",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab350b1c731d4a19b683d8e1dea0c9c8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/679M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyTextEmbedder:\n",
        "    def __init__(self, labels, text_model):\n",
        "        self.model = text_model\n",
        "        self.text_dict = dict()\n",
        "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        with torch.no_grad():\n",
        "            for txt in labels:\n",
        "                embed = self.model(txt)\n",
        "                text_features = embed[:,:512]\n",
        "                text_features = text_features.to(device)\n",
        "                self.text_dict[txt] = text_features\n",
        "    def get_cos(self, image_features, text_features):\n",
        "        cos = nn.CosineSimilarity(dim=1, eps=1e-32)\n",
        "        cosine=cos(image_features, text_features)\n",
        "        return cosine\n",
        "    def get_max_sim(self, image_features):\n",
        "        max = 0\n",
        "        label = ''\n",
        "        for txt in self.text_dict.keys():\n",
        "            text_features = self.text_dict[txt]\n",
        "            cosine = self.get_cos(image_features, text_features)\n",
        "            if cosine>max:\n",
        "                max = cosine\n",
        "                label = txt\n",
        "        return max, label\n",
        "    # def check_cos(self, image_features)\n"
      ],
      "metadata": {
        "id": "H9VdSTvCywli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_text_classes = [ 'crossroad','Normal traffic']\n",
        "my_text_classes2 = ['White police car in the traffic', 'No police car on the road']\n",
        "my_text_classes3 = ['Fire truck', 'No fire truck']\n",
        "my_text_classes4 = ['Spetial Car with flashing lights on the road', 'No Car with flashing lights']\n",
        "text_embedder = MyTextEmbedder(my_text_classes,text_model)\n",
        "police_embedder = MyTextEmbedder(my_text_classes2,text_model)\n",
        "fire_embedder = MyTextEmbedder(my_text_classes3,text_model)\n",
        "flash_embedder = MyTextEmbedder(my_text_classes4,text_model)\n",
        "\n",
        "def check_cos(image_features, text_features):\n",
        "    cos = nn.CosineSimilarity(dim=1, eps=1e-32)\n",
        "    cosine=cos(image_features, text_features)\n",
        "    return cosine \n",
        "def predict_img_emb(model, image_path):\n",
        "    image= preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
        "    image_features = model.encode_image(image)\n",
        "    return image_features\n",
        "import os\n",
        "\n",
        "def predict_video(video_path):\n",
        "    # labels_dict = { 'vehicle accident': 0,\n",
        "    #                'not vehicle accident': 0}\n",
        "    labels_dict = {name: 0 for name in my_text_classes}\n",
        "    labels_dict_2 = {name: 0 for name in my_text_classes2}\n",
        "    labels_dict_3 = {name: 0 for name in my_text_classes3}\n",
        "    labels_dict_4 = {name: 0 for name in my_text_classes4}\n",
        "    cur_img = 0\n",
        "    # police_car_cos =\n",
        "    for imgfile in os.listdir(video_path):\n",
        "        cur_img += 1\n",
        "        if cur_img % 10 != 0:\n",
        "            continue\n",
        "        img_path = os.path.join(video_path, imgfile)\n",
        "        img_emb = predict_img_emb(model, img_path)\n",
        "        max_val, max_label = text_embedder.get_max_sim(img_emb)\n",
        "\n",
        "        labels_dict[max_label] += 1\n",
        "\n",
        "        max_val, max_label = police_embedder.get_max_sim(img_emb)\n",
        "\n",
        "        labels_dict_2[max_label] += 1\n",
        "\n",
        "        max_val, max_label = fire_embedder.get_max_sim(img_emb)\n",
        "\n",
        "        labels_dict_3[max_label] += 1\n",
        "\n",
        "        max_val, max_label = flash_embedder.get_max_sim(img_emb)\n",
        "\n",
        "        labels_dict_4[max_label] += 1\n",
        "        print(check_cos(img_emb, text_embedder.text_dict['crossroad']))\n",
        "    super_max_label = ''\n",
        "    max_cnt = 0\n",
        "    for k in labels_dict.keys():\n",
        "        if labels_dict[k] > max_cnt:\n",
        "            max_cnt = labels_dict[k]\n",
        "            super_max_label = k\n",
        "    \n",
        "    # if labels_dict[my_text_classes[0]] > 10:\n",
        "    #     return my_text_classes[0]\n",
        "    labels = []\n",
        "    if labels_dict[my_text_classes[0]] >= 1/3 * (labels_dict[my_text_classes[0]] + labels_dict[my_text_classes[1]]):\n",
        "        labels.append(my_text_classes[0])\n",
        "    else:\n",
        "        labels.append(my_text_classes[1])\n",
        "    # labels.append(super_max_label)\n",
        "    if labels_dict_2[my_text_classes2[0]] > 4:\n",
        "        labels.append(my_text_classes2[0])\n",
        "    else:\n",
        "        labels.append(my_text_classes2[1])\n",
        "\n",
        "    if labels_dict_3[my_text_classes3[0]] > 4:\n",
        "        labels.append(my_text_classes3[0])\n",
        "    else:\n",
        "        labels.append(my_text_classes3[1])\n",
        "    \n",
        "    if labels_dict_4[my_text_classes4[0]] > 4:\n",
        "        labels.append(my_text_classes4[0])\n",
        "    else:\n",
        "        labels.append(my_text_classes4[1])\n",
        "    print(labels_dict, labels_dict_2, labels_dict_3, labels_dict_4)\n",
        "    return labels\n",
        "\n"
      ],
      "metadata": {
        "id": "UF6KkmOp8EXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = 0\n",
        "cnt = 0\n",
        "for video in sorted(list(os.listdir('/content/drive/MyDrive/ivision/parser_video_dtp_5_720p'))):\n",
        "    video_label = predict_video(os.path.join('/content/drive/MyDrive/ivision/parser_video_dtp_5_720p', video))\n",
        "    print(video, ':')\n",
        "    true_label = ''\n",
        "    \n",
        "    if int(video) in dtp_ids:\n",
        "        print('True label:', my_text_classes[0])\n",
        "        true_label = my_text_classes[0]\n",
        "    else:\n",
        "        print('True label:', my_text_classes[1])\n",
        "        true_label = my_text_classes[1]\n",
        "    print('Predicted label:', video_label)\n",
        "    acc += int(video_label[0] == true_label)\n",
        "\n",
        "    print('----------------',cnt,'/', 50, '----------------------')\n",
        "\n",
        "    cnt += 1\n",
        "print(acc / 50 * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "00-VBfjS88Cm",
        "outputId": "65b3f7e7-a8a1-4b52-a324-0e3f5c5c29e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.2515], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2536], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2546], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2435], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2540], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2583], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2539], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2516], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2517], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2479], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'crossroad': 10, 'Normal traffic': 0} {'White police car in the traffic': 5, 'No police car on the road': 5} {'Fire truck': 0, 'No fire truck': 10} {'Spetial Car with flashing lights on the road': 2, 'No Car with flashing lights': 8}\n",
            "1 :\n",
            "True label: Normal traffic\n",
            "Predicted label: ['crossroad', 'White police car in the traffic', 'No fire truck', 'No Car with flashing lights']\n",
            "---------------- 0 / 50 ----------------------\n",
            "tensor([0.2647], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2733], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2690], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2668], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2783], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2805], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2767], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2616], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2735], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2736], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2777], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2666], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2713], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2792], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2654], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2723], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2809], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2745], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2659], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2666], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2760], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2705], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2604], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2673], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2650], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2677], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2615], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2599], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2676], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'crossroad': 29, 'Normal traffic': 0} {'White police car in the traffic': 13, 'No police car on the road': 16} {'Fire truck': 0, 'No fire truck': 29} {'Spetial Car with flashing lights on the road': 25, 'No Car with flashing lights': 4}\n",
            "10 :\n",
            "True label: crossroad\n",
            "Predicted label: ['crossroad', 'White police car in the traffic', 'No fire truck', 'Spetial Car with flashing lights on the road']\n",
            "---------------- 1 / 50 ----------------------\n",
            "tensor([0.2313], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2299], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2331], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2305], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2298], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2340], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2331], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2337], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2362], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2307], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2377], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2315], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2327], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2279], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2332], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2310], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2327], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2289], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2272], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'crossroad': 11, 'Normal traffic': 8} {'White police car in the traffic': 19, 'No police car on the road': 0} {'Fire truck': 0, 'No fire truck': 19} {'Spetial Car with flashing lights on the road': 1, 'No Car with flashing lights': 18}\n",
            "11 :\n",
            "True label: crossroad\n",
            "Predicted label: ['crossroad', 'White police car in the traffic', 'No fire truck', 'No Car with flashing lights']\n",
            "---------------- 2 / 50 ----------------------\n",
            "tensor([0.2402], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2424], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2398], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2409], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2390], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2407], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2384], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2447], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2369], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2393], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2472], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2457], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2364], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2431], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2409], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2394], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2382], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2447], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2420], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'crossroad': 19, 'Normal traffic': 0} {'White police car in the traffic': 14, 'No police car on the road': 5} {'Fire truck': 0, 'No fire truck': 19} {'Spetial Car with flashing lights on the road': 0, 'No Car with flashing lights': 19}\n",
            "12 :\n",
            "True label: crossroad\n",
            "Predicted label: ['crossroad', 'White police car in the traffic', 'No fire truck', 'No Car with flashing lights']\n",
            "---------------- 3 / 50 ----------------------\n",
            "tensor([0.2072], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2159], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2118], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2092], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2231], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2232], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2056], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2087], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2015], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2084], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2138], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2114], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2244], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2190], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2160], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'crossroad': 13, 'Normal traffic': 2} {'White police car in the traffic': 15, 'No police car on the road': 0} {'Fire truck': 0, 'No fire truck': 15} {'Spetial Car with flashing lights on the road': 8, 'No Car with flashing lights': 7}\n",
            "13 :\n",
            "True label: crossroad\n",
            "Predicted label: ['crossroad', 'White police car in the traffic', 'No fire truck', 'Spetial Car with flashing lights on the road']\n",
            "---------------- 4 / 50 ----------------------\n",
            "tensor([0.2674], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2573], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2528], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2596], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2586], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2606], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2567], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2699], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2724], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2681], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2720], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2690], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2655], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2680], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2687], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2716], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'crossroad': 16, 'Normal traffic': 0} {'White police car in the traffic': 11, 'No police car on the road': 5} {'Fire truck': 0, 'No fire truck': 16} {'Spetial Car with flashing lights on the road': 0, 'No Car with flashing lights': 16}\n",
            "14 :\n",
            "True label: crossroad\n",
            "Predicted label: ['crossroad', 'White police car in the traffic', 'No fire truck', 'No Car with flashing lights']\n",
            "---------------- 5 / 50 ----------------------\n",
            "tensor([0.2536], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2403], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2427], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2427], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2472], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2493], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2546], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2535], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2551], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2479], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2473], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2540], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2623], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'crossroad': 13, 'Normal traffic': 0} {'White police car in the traffic': 12, 'No police car on the road': 1} {'Fire truck': 0, 'No fire truck': 13} {'Spetial Car with flashing lights on the road': 0, 'No Car with flashing lights': 13}\n",
            "15 :\n",
            "True label: crossroad\n",
            "Predicted label: ['crossroad', 'White police car in the traffic', 'No fire truck', 'No Car with flashing lights']\n",
            "---------------- 6 / 50 ----------------------\n",
            "tensor([0.2440], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2392], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2437], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2429], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2428], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2464], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2495], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2440], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2451], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2489], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2428], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2439], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2424], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'crossroad': 13, 'Normal traffic': 0} {'White police car in the traffic': 13, 'No police car on the road': 0} {'Fire truck': 0, 'No fire truck': 13} {'Spetial Car with flashing lights on the road': 13, 'No Car with flashing lights': 0}\n",
            "16 :\n",
            "True label: Normal traffic\n",
            "Predicted label: ['crossroad', 'White police car in the traffic', 'No fire truck', 'Spetial Car with flashing lights on the road']\n",
            "---------------- 7 / 50 ----------------------\n",
            "tensor([0.2625], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2607], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2644], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2566], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2541], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2688], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2550], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2654], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2682], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2637], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2595], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2653], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2644], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2578], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'crossroad': 14, 'Normal traffic': 0} {'White police car in the traffic': 6, 'No police car on the road': 8} {'Fire truck': 0, 'No fire truck': 14} {'Spetial Car with flashing lights on the road': 0, 'No Car with flashing lights': 14}\n",
            "17 :\n",
            "True label: Normal traffic\n",
            "Predicted label: ['crossroad', 'White police car in the traffic', 'No fire truck', 'No Car with flashing lights']\n",
            "---------------- 8 / 50 ----------------------\n",
            "tensor([0.2519], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2560], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2516], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2548], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2515], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2430], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2553], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2488], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2498], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2501], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2492], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2461], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2543], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'crossroad': 13, 'Normal traffic': 0} {'White police car in the traffic': 13, 'No police car on the road': 0} {'Fire truck': 0, 'No fire truck': 13} {'Spetial Car with flashing lights on the road': 13, 'No Car with flashing lights': 0}\n",
            "18 :\n",
            "True label: Normal traffic\n",
            "Predicted label: ['crossroad', 'White police car in the traffic', 'No fire truck', 'Spetial Car with flashing lights on the road']\n",
            "---------------- 9 / 50 ----------------------\n",
            "tensor([0.2639], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2554], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2621], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2684], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2540], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2554], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2540], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2610], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2817], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2648], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2669], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2549], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2662], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'crossroad': 9, 'Normal traffic': 4} {'White police car in the traffic': 12, 'No police car on the road': 1} {'Fire truck': 0, 'No fire truck': 13} {'Spetial Car with flashing lights on the road': 0, 'No Car with flashing lights': 13}\n",
            "19 :\n",
            "True label: Normal traffic\n",
            "Predicted label: ['crossroad', 'White police car in the traffic', 'No fire truck', 'No Car with flashing lights']\n",
            "---------------- 10 / 50 ----------------------\n",
            "tensor([0.2753], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2765], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2627], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2446], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2472], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2541], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2408], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2359], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2845], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2366], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2378], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2357], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2325], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2309], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2325], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2251], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2313], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2305], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2851], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2261], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2212], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2799], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2815], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2736], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2795], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2823], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2779], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2841], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2648], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'crossroad': 29, 'Normal traffic': 0} {'White police car in the traffic': 15, 'No police car on the road': 14} {'Fire truck': 19, 'No fire truck': 10} {'Spetial Car with flashing lights on the road': 13, 'No Car with flashing lights': 16}\n",
            "2 :\n",
            "True label: crossroad\n",
            "Predicted label: ['crossroad', 'White police car in the traffic', 'Fire truck', 'Spetial Car with flashing lights on the road']\n",
            "---------------- 11 / 50 ----------------------\n",
            "tensor([0.2414], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2422], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2348], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2388], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2431], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2422], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2427], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2403], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2442], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2603], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2461], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2388], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2418], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'crossroad': 1, 'Normal traffic': 12} {'White police car in the traffic': 13, 'No police car on the road': 0} {'Fire truck': 0, 'No fire truck': 13} {'Spetial Car with flashing lights on the road': 11, 'No Car with flashing lights': 2}\n",
            "20 :\n",
            "True label: Normal traffic\n",
            "Predicted label: ['Normal traffic', 'White police car in the traffic', 'No fire truck', 'Spetial Car with flashing lights on the road']\n",
            "---------------- 12 / 50 ----------------------\n",
            "tensor([0.2639], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2418], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2486], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2533], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2381], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2354], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2530], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2448], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2575], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2577], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2496], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2434], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2571], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2652], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2786], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2522], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2526], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2552], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2505], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2603], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2538], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2656], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2555], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2564], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2454], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2469], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "{'crossroad': 25, 'Normal traffic': 1} {'White police car in the traffic': 6, 'No police car on the road': 20} {'Fire truck': 0, 'No fire truck': 26} {'Spetial Car with flashing lights on the road': 26, 'No Car with flashing lights': 0}\n",
            "21 :\n",
            "True label: crossroad\n",
            "Predicted label: ['crossroad', 'White police car in the traffic', 'No fire truck', 'Spetial Car with flashing lights on the road']\n",
            "---------------- 13 / 50 ----------------------\n",
            "tensor([0.2685], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2749], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2724], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2755], device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor([0.2677], device='cuda:0', grad_fn=<DivBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-1c739b9f3949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ivision/parser_video_dtp_5_720p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mvideo_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ivision/parser_video_dtp_5_720p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrue_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-777068e4442c>\u001b[0m in \u001b[0;36mpredict_video\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mimg_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_img_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mmax_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_embedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_max_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-777068e4442c>\u001b[0m in \u001b[0;36mpredict_img_emb\u001b[0;34m(model, image_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcosine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_img_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mimage_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    417\u001b[0m             )\n\u001b[1;32m    418\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mnew_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_short\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_long\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_long\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_short\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1903\u001b[0m                 )\n\u001b[1;32m   1904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SuasJ5jE1rLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def max_cosine_text(image_path,labels):\n",
        "    \"\"\"\n",
        "    image_path: путь к изображению для которго ищем\n",
        "    text: текстовые метки для которы ищем\n",
        "    \"\"\"\n",
        "    cos = nn.CosineSimilarity(dim=1, eps=1e-32)\n",
        "    # print(1)\n",
        "    t = time.time()\n",
        "    image= preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
        "    print('Время обработки: ', time.time() - t)\n",
        "\n",
        "  \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        max = 0\n",
        "        label = ''\n",
        "        image_features = model.encode_image(image)\n",
        "        print('После картинки: ', time.time() - t)\n",
        "        for txt in labels:\n",
        "            t = time.time()\n",
        "            embed = text_model(txt)\n",
        "            print('После текста: ', time.time() - t)\n",
        "            text_features = embed[:,:512]\n",
        "            text_features = text_features.to(device)\n",
        "            \n",
        "            cosine=cos(image_features,text_features)\n",
        "            \n",
        "            if cosine>max:\n",
        "                max = cosine\n",
        "                label = txt\n",
        "        \n",
        "\n",
        "    \n",
        "    return max,label"
      ],
      "metadata": {
        "id": "h9lFslv3qety"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "97E2BGtE2RqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EDTN7O3b11z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DExDPtCw1AQG"
      },
      "source": [
        "# Multiply text input"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "1ifRtFzD3ZvT",
        "outputId": "379bcf0b-3a3e-4f5b-f29b-d97db9fdf3ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 :\n",
            "True label: vehicle accident\n",
            "Predicted label: have not emergency car\n",
            "10 :\n",
            "True label: vehicle accident\n",
            "Predicted label: have not emergency car\n",
            "11 :\n",
            "True label: vehicle accident\n",
            "Predicted label: have not emergency car\n",
            "12 :\n",
            "True label: vehicle accident\n",
            "Predicted label: have not emergency car\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-ba1ff7b54a63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvideo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ivision/parsed_videos/parser_video_dtp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mvideo_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ivision/parsed_videos/parser_video_dtp'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrue_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-7d68f8cc7512>\u001b[0m in \u001b[0;36mpredict_video\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimgfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mimg_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_img_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmax_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_embedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_max_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlabels_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_label\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-99994544fcd4>\u001b[0m in \u001b[0;36mpredict_img_emb\u001b[0;34m(model, image_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict_img_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimage_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mPIL\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRescaled\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    417\u001b[0m             )\n\u001b[1;32m    418\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mnew_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_short\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_long\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_long\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_short\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1884\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1886\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreducing_gap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresample\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNjqP-yipi4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "521aaae5-ea96-4d14-85b3-fd024085ab8e"
      },
      "source": [
        "t3 = time.time()\n",
        "max_cosine_text('/content/2008-03-11_Bicyclist_in_Carrboro.jpg',[ 'vehicle accident','not vehicle accident'])\n",
        "print(time.time() - t3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время обработки:  0.060974836349487305\n",
            "После картинки:  0.07175993919372559\n",
            "После текста:  0.06282615661621094\n",
            "После текста:  0.060387611389160156\n",
            "0.19846367835998535\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_time / 100"
      ],
      "metadata": {
        "id": "JY9EYrSSar4p",
        "outputId": "549897bf-7321-4bf6-e4b9-f9804b3f957c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20537013053894043"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1FY8xYu08Vq"
      },
      "source": [
        "# Multiply image input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c9bUd4O1tSL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c4c876-1033-404d-d5ad-a6fe820ed25e"
      },
      "source": [
        "_ , _ ,path =max_cosine_images(['/content/Prm_VJ_fig1_featureTypesWithAlpha.png','/content/2008-03-11_Bicyclist_in_Carrboro.jpg'],'велосипед')\n",
        "\n",
        "print(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/2008-03-11_Bicyclist_in_Carrboro.jpg\n"
          ]
        }
      ]
    }
  ]
}